\documentclass{article}

\title{Chapter 5 Exercises}
\usepackage{dztex}
\usepackage{cleveref}
\usepackage{amssymb} % \rightrightarrows

\fancyhead[L]{Set-Valued, Convex and Nonsmooth Analysis in Dynamics and Control \vspace{1mm}}

\newenvironment{ex}[1]
  {\renewcommand\theexercise{#1}\exercise}
  {\endexercise}

\newcommand{\B}{\mathbb{B}}
\newcommand{\ik}{i_k}
\DeclareMathOperator*{\argmin}{arg min}
\DeclareMathOperator*{\gph}{gph}
\DeclareMathOperator*{\sgn}{sgn}
\DeclareMathOperator*{\spn}{span}
\DeclareMathOperator*{\inte}{Int}
\DeclareMathOperator*{\con}{con}
\newcommand{\clo}[1]{\overline{#1}}
\newcommand{\R}[1]{\mathbb{R}^{#1}}
\newcommand{\mr}{\mathcal{R}}
\newcommand{\idot}[2]{#1 \cdot #2}
\newcommand{\pdot}[2]{\parens{#1 \cdot #2}}

\begin{document}
\begin{ex}{5.1} %;
  First we want to show a lexographically minimal point exists. By compactness of $K$ it's bounded and closed. Projecting onto the first coordinate we get another bounded closed $1D$ set so that there's a minimal element. Call it $u_1$. Now consider $K_1 := K \cap \braces{ x_1 = u_1 }$, i.e. the intersection with the hyperplane specified by $x_1 = u_1$. This is closed since its the intersection of closed sets \& bounded because a subset of a bounded set, hence compact. Project $K_1$ onto its second coordinate to get another $1D$ compact set, hence with a minimal element $u_2$. We can iteratively do this $m$ times to come up with $u = (u_1, u_2, ..., u_m)$. By construction this is lexographically minimal. \, \\

  Now suppose there's a second point $w$ that's also lexographically minimal. By the definition of lexographic minimality of $u$ for some $i$ one of $u_i < w_i$. This means $w$ is not lexographically smaller than $u$, hence it's not lexographically minimal.
\end{ex} %:
\begin{ex}{5.3} %;
  The proof of this is very similar to Lemma 5.2. Put $A \subset [0, T]$ where $\dot{\phi}(t) \in F(\phi(t))$ for $t \in A$. Define $v(t) = \dot{\phi(t)}$ for $t \in A$ and for every $t \not\in A$ pick arbitrary $u^*(t) \in U(\phi(t))$ and  put $v(t) = f(\phi(t), u(t))$ then $v : [0, T] \to \R{n}$ where $v(t) = \dot{\phi}(t)$ a.e. $t$ and hence $v$ is measurable. Define $M : [0, T] \rightrightarrows U(\phi([0, T]))$ by
  $$
  M(t) = \begin{cases}
    \braces{ u \in U(\phi(t)) \mid v(t) = f(\phi(t), u) } & t \in A \\
    \braces{ u^*(t) } & t \in [0, T] \setminus A
  \end{cases}
  $$
  We have the following properties on $M$ at each $t \in A$:
  \begin{itemize}
    \item $M(t)$ is non-empty by construction of $v$
    \item Since $\phi([0, T])$ is bounded, $U$ is locally bounded, Exercise 2.12 tells us $U(\phi([0, T]))$ is bounded, hence $M(t)$ is bounded.
    \item We want to show each $M(t)$ is also closed so that $M(t)$ is compact. Let $u_i \in M(t)$ where $u_i \to u$. By definition of $M(t)$ we know $u_i \in U(\phi(t))$, and so by osc we know $u \in U(\phi(t))$ (our sequence in the domain is the constant sequence $\phi(t) \to \phi(t)$). Continuity of $f$ gives us $v(t) = f(\phi(t), u)$, so that $u \in M(t)$ and thus $M(t)$ is compact.
  \end{itemize}
  Trivially all the above conclusions follow for $t \not\in [0, T] \setminus A$, so that $M$ takes compact non-empty values. Just as in Lemma 5.2 define $u(t)$ as the lexographic minimal value in $M(t)$. We have $u : [0, t] \to U(\phi([0, T]))$ so that
  $$
  v(t) = f(\phi(t), u(t)) \; \forall t \in [0, T]
  $$
  All that's left to show is that $u$ is measurable. We do this just like in Lemma 5.2 inductively with Lusin's Theorem. We start again with $u_1, u_2, ... u_{k-1}$ coordinate functions measurable and will show $u_k$ is measurable. Pick $\epsilon > 0$. Lusin's Theorem gives us a compact $C \subset [0, T]$ so that $t \mapsto (u_1(t), u_2(t), ..., u_{k-1}(t), v(t))$ is continuous and $\mu([0, T] \setminus C) < \epsilon / 2$. Notably each $u_1, u_2, ..., u_{k-1}, v$ are continuous on $C$. \, \\

  Now the goal is to show for arbitrary $r$ the set
  $$
  S := \braces{ t \in C \mid u_k(t) \le r }
  $$
  is closed. If this is the case then we can show our claim the same way the end of Lemma 5.2 does after showing this set is closed. \, \\

  To this end, suppose $S$ is not closed, so that $\exists t_i \to \tau$ where $t_i \in S$. Since $C$ is closed and $t_i \in C$ we know $\tau \in C$. Because $U$ is locally bounded $u(t_i)$ is bounded and hence there's a convergent subsequence. Without relabeling we have $u(t_i) \to \clo{u}$, and by osc of $U$ we know $\clo{u} \in U(\tau)$. Continuity of $f, \phi$ tells us $f(\phi(t_i), u(t_i)) \to f(\phi(\tau), \clo{u})$ so that $\clo{u} \in M(\tau)$. \, \\

  Continuity of $u_1, u_2, ..., u_{k-1}$ on $C$ gives us $\clo{u}_i = u_i(\tau)$ for $i = 1, 2, ..., k-1$. However, by our initial assumption $u_k(\tau) > r$, and since $u(t_i)_k \le r \implies \clo{u}_k \le r$ so that
  $$
  u_k(\tau) > \clo{u}_k,
  $$
  but this contradicts the fact that $u(\tau)$ is lexographically minimal in $M(\tau)$ (since $\clo{u} \in M(\tau)$), hence indeed $S$ is closed.
\end{ex} %:
\begin{ex}{5.4} %;
  \begin{enumerate}
    \item[(a)]
      The forward implication comes from the definition of $\sup$. To prove the backward one, we start with $v$ so that $\idot{v}{p} \le \sup_{w \in C} \idot{w}{p}$ for every $p \in \R{n}$. Suppose for contradiction $v \not\in C$. By Theorem 4.16 that $\exists p \in \R{n}, \epsilon > 0$ so that
      $$
      \idot{w}{p} + \epsilon \le \idot{v}{p} \; \forall w \in C \implies \sup_{w\in C} \idot{w}{p} + \epsilon \le \idot{v}{p}
      $$
      which contradicts the initial assumption, so $v \in C$.
    \item[(b)]
      \begin{itemize}
        \item
          Let $(x_i, p_i) \to (x, p) \in C \times \R{n}$. Because $F$ is locally bounded $H(x_n, p_n)$ is finite. Thus, for each $n$, by definition of $\sup$ $\exists v_n \in F(x_n)$ where
          $$
          \sup_{v \in F(x_n)} \idot{v}{p_n} - \frac{1}{n} \le \idot{v_n}{p_n} \implies \limsup_{n \to \infty} H(x_n, p_n) \le \limsup_{n \to \infty} \idot{v_n}{p_n}
          $$
          Next, by definition of $\limsup$ $\exists \idot{v_{n_k}}{p_{n_k}} \to \limsup_{n \to \infty} \idot{v_n}{p_n}$. Since $F$ is locally bounded $\exists v_{n_{k_i}} \to \nu$, and by osc $\nu \in F(x)$. Using the fact that $p_n \to p$ we see $\idot{v_{n_k}}{p_{n_k}} \to \idot{\nu}{p}$ and so $\idot{\nu}{p} = \limsup_{n \to \infty} \idot{v_n}{p_n}$. Combined with the definition of $\sup$, the fact that $\nu \in F(x)$ means
          $$
          \limsup_{n \to \infty} \idot{v_n}{p_n} = \idot{\nu}{p} \le \sup_{v \in F(x)} \idot{v}{p} = H(x, p)
          $$
          Pulling in the initial major expression above we find our desired result
          $$
          \limsup_{n \to \infty} H(x_n, p_n) \le H(x, p)
          $$
        \item
          Let $p_n \to p \in C$. By the definition of $\sup$ we can construct, $v_n \in F(x)$ so that $\idot{v_n}{p} \to \sup_{v \in F(x)} \idot{v}{p}$. By osc and local boundedness of $F$ there's a convergent subsequence so that
          $$
          v_{n_i} \to \nu \in F(x) \implies \idot{v_n}{p} \to \idot{\nu}{p}
          $$
          We also have
          $$
          \idot{\nu}{p_n} \le \sup_{v \in F(x)} \idot{v}{p_n} \implies \liminf_n \idot{\nu}{p_n} \le \liminf_n \sup_{v \in F(x)} \idot{v}{p_n} = \liminf_n H(x, p_n)
          $$
          So that combining $\liminf_n \idot{\nu}{p_n} = \idot{\nu}{p} = H(x, p)$, and usc of $H$ our claim is shown since
          $$
          \limsup_n H(x, p_n) \le H(x, p) \le \liminf_n H(x, p_n) \implies H(x, p_n) \to H(x, p)
          $$
      \end{itemize}
  \end{enumerate}
\end{ex} %:
\begin{ex}{5.12} %;
  Let $T$ be given. For each $n$ partition $[0, T]$ by $n$ $\frac{T}{n}$ intervals. For each $n$ fix
  $$
  \phi_n(t) = \begin{cases}
    0 & t = 0 \\
    -t + 2k\frac{T}{n} & t \in \left( 2k\frac{T}{n}, \parens{2k+1}\frac{T}{n} \right], k \in \mathbb{N} \\
    t - \parens{2k+2}\frac{T}{n} & t \in \left( \parens{2k+1}\frac{T}{n}, \parens{2k+2}\frac{T}{n} \right], k \in \mathbb{N} \\
  \end{cases}
  $$
  Then within each partition continuity is clear. At each $2k\frac{T}{n}$ from the left $\phi_n(t)$ is either $0$ when $k=0$ or $t - 2k\frac{T}{n} \to 0$ as $t \to 2k\frac{T}{n}$, and similarly $\phi_n(t) = -t + 2k\frac{T}{n} \to 0$ as $t \to 2k\frac{T}{n}$ from the right. A similar calculation shows that the function continuously takes the value $-\frac{T}{n}$ when $t = \parens{2k+1}\frac{T}{n}$. It's clear $\phi_n$ converges uniformly to the zero function since the max value vanishes. Similarly the partition's size is $\frac{T}{n} \to 0$. This tells us $\phi = 0$ is an Euler solution.
\end{ex} %:
\begin{ex}{5.13} %;
  From $(-1,-1)$ the solution must stay on the $y=x$ line, i.e. for $(0, \tau)$ $\phi(t) = (1, 1)t$, where $\tau = \min\{T, 1\}$. If $\tau = T < 1$ then this is the only possible solution. Assuming $T > 1$, though, we can have two solutions on $t \in [1, T]$: $\phi(t) = (1, 0)t - (1, 0)$ or $\phi(t) = (1, 1)t - (1, 1)$. \, \\

  The former solution comes from a sequence of partitions which all contain $t=1$. This ensures the sequence of solutions must solutions abide by $\phi(t) = (1, 0)t - (1, 0)$ for $t \in (1, 1+\epsilon)$, which perpetuates that same solution until $t = T$. \, \\

  The latter solution comes by ensuring $t = 1$ is not in the partitioning so that solutions stay on the $y=x$ line at all times (i.e. the "problem" point at $t = 1$ is skipped over by the "approximation" done by $(1, 1)t$)
\end{ex} %:
\begin{ex}{5.14} %;
  \begin{itemize}
    \item
      Let $x_0 \in \R{n}$. Since $f$ is locally bounded there's some $R$ s.t. $f(x_0 + R\B)$ is bounded, so fix $M = \max_{x \in x_0 + R\B} f(x)$. Put $T := \frac{R}{M}$. For each $n \in \mathbb{N}$ consider a uniform partition of $[0, T]$ by $n$ segments of length $\tau_n := \frac{T}{n}$. Put $\tau_{n,i} = i \tau_n$ and construct $\phi_n$ as follow; for $t \in [0, \tau_{n, 1}]$
      $$
      \phi_n(t) = x_0 + t f(x_0)
      $$
      Next for each $i = 1, 2, ..., n-1$ put $x_{n,i} := \phi_n(\tau_{n, i})$. where $\phi_n$ is given for $t \in (\tau_{n,i}, \tau_{n,i+1}]$ by
      $$
      \phi_n(t) = x_{n,i} + (t - \tau_{n,i}) f(x_{n,i})
      $$
      Notice $x_{n,1} = x_0 + \tau_{n,1}f(x_0) \in x_0 + \frac{T}{n} M \B = x_0 + \frac{R}{n} \B$ and for $i = 2, ... n-1$
      $$
      x_{n, i} = \phi(\tau_{n,i}) = x_{n,i-1} + \frac{T}{n} f(x_{n,i-1}) \in x_{n,i-1} + \frac{T}{n} M \B = x_{n,i-1} + \frac{R}{n} \B
      $$
      so that each $x_{n,i} \in x_0 + \frac{iR}{n}$. Consequently $\phi_n([0, \tau_{n,1}]) \subset x_0 + \frac{T}{n} M \B = x_0 + \frac{R}{n} \B$ and for $i = 1, 2, ... n-1$
      $$
      \phi_n((\tau_{n, i}, \tau_{n, i+1}]) \subset x_0 + \frac{iR}{n} \B + \frac{T}{n} M \B = x_0 + \frac{(i+1)R}{n} \B
      $$
      so that $\phi_n([0, T]) \subset x_0 + R \B$. \, \\

      Of note: as compared to Theorem 5.11 we don't need to worry about well-formedness of $x_{n,i}$ because $\textrm{dom} \, f = \R{n}$. \, \\

      It's easy to see each $\phi_n$ is an Euler Polygonal approximation for $\dot{x} = f(x)$. Additionally for each $i = 0, 1, ..., n-1$ on $(\tau_{n,i}, \tau_{n,i+1})$
      $$
      \dot{\phi_n}(t) = f(x_{n, i}) \implies \norm{\dot{\phi_n}(t)} \le M \; \text{ a.e. } t \in [0, T]
      $$
      Combined with the fact that $x_0 + R \B$ is compact and $\phi_n([0, T]) \subset x_0 + R \B$ Lemma 5.6 gives us a uniformly convergent subsequence of $\phi_n$ to some $\phi$, thus an Euler solution to (5.13). \, \\
    \item
      Given $T$ and an Euler solution $\phi$ on $[0, T]$ with $\phi_i$ which converge uniformly to $\phi$. We know, thanks to local boundedness we know $\phi_i$ are bounded. Additionally $F_K$ satisifies the Basic Assumptions as it trivially takes non-empty convex values, is locally bounded because $f$ is locally bounded and osc comes easily because the intersection of closed sets is closed. Lastly because $\phi$ is an Euler solution trivially
      $$\dot{\phi_i}(t) \in F_K(\phi(t)) \text{ a.e. } t \in [0, T]$$
      Since $\phi_i$ converge uniformly Theorem 5.7 tells us $\phi$ is a solution to $\dot{x} \in F_K(x)$ with $x(0) = x_0$. Lastly for $\phi$ to be a Krasovskii solution we need $\phi$ to be absolutely continuous. \, \\

      Boundedness tells us $\phi_n([0, T]) \in M \B$ for some $M$, and local boundedness of $f$ tells us $\norm{\dot{\phi}(t)} \le L$ for some finite $L$, a.e. $t \in [0, T]$. Thus, Lemma 5.6 tells us $\phi$ is absolutely continuous so that the claim is shown.
  \end{itemize}
\end{ex} %:
\begin{ex}{5.24} %;
  We know
  $$
  \omega(\phi) = \limsup_{i \to \infty} \phi\parens{[i, \infty)} = \lim_{i \to \infty} \phi\parens{[i, \infty)}
  $$
  where the second equality comes because $\left.\phi\parens{[i, \infty)}\right|_i$ is non-increasing. This tells us $\omega(\phi)$ is closed. Since $\phi$ is bounded, $\forall i$ $\phi([i, \infty)) \subset R\B$ for some $R > 0$ so that $\omega(\phi)$ is bounded, and thus compact. In particualr $\phi(i)$ has a convergent subsequence in $R\B$ and so $\omega(\phi)$ is also non-empty. \, \\

  To show $\omega(\phi)$ is weakly forward invariant let $x_0 \in \omega(\phi)$ s.t. $\exists t_k \to \infty$ and $\phi(t_k) \to x_0$. Put
  $$
  \phi_k(t) = \phi(t_k + t) \implies \dot{\phi_k(t)} = \dot{\phi(t_k+t)} \in F(\phi(t_k+t)) = F(\phi_k(t))
  $$
  thus each $\phi_k$ is a solution to (5.1). Since $\phi$ is bounded, $\phi_k$ are bounded so that we can invoke Theorem 5.7. That gives us a uniformly convergent subsequence of $\phi_k$ converging to some $\psi : [0, \infty) \to \R{n}$ s.t. $\psi$ is a solution to (5.1). Lastly
  $$
  \psi(t) = \lim_{k \to \infty} \phi_k(t) = \lim_{k \to \infty} \phi(t_k + t) \in \limsup_{k \to \infty} \phi([t_k, \infty)) \subset \limsup_{k \to \infty} \phi([k, \infty)) = \omega(\phi)
  $$
  so $\mathrm{rng}(\phi) \subset \omega(\phi)$ showing that $\omega(\phi)$ is weakly forward invariant.
\end{ex} %:
\begin{ex}{5.27} %;
  Consider
  $$
  F(x, y) = \braces{(-1, \abs{x}), (1, \abs{x})}
  $$
  Let $T > 0$ and consider a solution $(x(t), y(t)) := \phi(t) \in \mathcal{S}_{[0, T]}$. Since $\dot{y} > 0$, MVT tells us $y$ is strictly increasing and so $y(t) > 0 \; \forall t > 0$, hence $y(T) > 0 \implies  y(T) \ne 0$. \, \\

  Now consider for each $n$ a solution $\phi_n$ constructed as follows: split $[0, T]$ into $2n$ equal subintervals. On the odd subintervals (starting with the first subinterval have the solution adide by $(1, \abs{x})$ and on the even abide by $(-1, \abs{x})$. Then to start, with $(x_n(t), y_n(t)) := \phi_n(t)$
  $$
  \dot{x_n(t)} = 1 \implies x_n(t) = t, \, \dot{y_n(t)} = \abs{x_n(t)} = t \implies y_n(t) = \frac{t^2}{2} \implies \phi\parens{\frac{T}{2n}} = \parens{\frac{T}{2n}, \frac{T^2}{8n^2}}
  $$
  For the next sub interval I'll use relative $t$, i.e. again starting with $t=0$, but now we'll move according to $(-1, \abs{x})$ for $T/2n$ but with a start point of $\parens{\frac{T}{2n}, \frac{T^2}{8n^2}}$, so
  $$
  \dot{x_n(t)} = -1 \implies x_n(t) = \frac{T}{2n} - t, \, \dot{y_n(t)} = \frac{T}{2n} - t \implies y_n(t) = \frac{T}{2n}t - \frac{t^2}{2} + \frac{T^2}{8n^2}
  $$
  so that $\phi_n\parens{\frac{2T}{2n}} = \parens{0, \frac{T^2}{4n^2} - \frac{T^2}{8n^2} + \frac{T^2}{8n^2}} = \parens{0, \frac{T^2}{4n^2}}$. Repeating this pair of operations $n$ times to span the full $T$ interval will end us at
  $$
  \phi_n(T) = \parens{0, \frac{nT^2}{4n^2}} = \parens{0, \frac{T^2}{4n}} \in \mathcal{R}_{(0, 0)}
  $$
  As $n \to \infty$, though $\phi_n(T) \to (0, 0)$, but as shown above, $(0, 0) \not\in \mathcal{R}_{(0, 0)}$, so that $\mathcal{R}_{(0, 0)}$ is not closed. \, \\

  As mentioned over email briefly, I'm still unsure of myself on this exercise. I don't intuitively understand what's going on... I more of less feel like I'm reciting a speech. I also struggled with how to write this up... was it ok to work "relatively" at each subinterval? I found the computations were very tedious if I tried to use the "absolute" domain at each step. At the same time, it might be the case that working "relatively" has lead me to an incorrect solution. Anyway, I'm glad this exercise is over... for now, until we chat about it again. So far in this class, this exercise takes the prize for my nemesis.
\end{ex} %:
\end{document}
